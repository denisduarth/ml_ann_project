{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 1: Projeto Machine Learning (Algorítmo de Classificação)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "  accuracy_score,\n",
    "  confusion_matrix,\n",
    "  ConfusionMatrixDisplay,\n",
    "  f1_score,\n",
    "  classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Versão VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv', delimiter=',')\n",
    "df = df.drop(columns=['Person ID', 'Daily Steps', 'Heart Rate', 'Blood Pressure', 'BMI Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Versão Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/Sleep_health_and_lifestyle_dataset.csv', delimiter=';')\n",
    "# df = df.drop(columns=['Unnamed: 13','Unnamed: 14', 'Person ID', 'Daily Steps', 'Heart Rate', 'Blood Pressure', 'BMI Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Trocando valores string por valores inteiros em cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace(['Male', 'Female'], list(range(len(df['Gender'].unique()))))\n",
    "df['Sleep Disorder'] = df['Sleep Disorder'].replace(['None', 'Sleep Apnea', 'Insomnia'], (list(range(len(df['Sleep Disorder'].unique())))))\n",
    "df['Occupation'] = df['Occupation'].replace(df['Occupation'].unique(), list(range(len(df['Occupation'].unique())))) # type: ignore\n",
    "df['Sleep Disorder'].fillna(np.floor(df['Sleep Disorder'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criando a coluna \"Classe\" a partir da coluna \"Quality of Sleep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[df['Quality of Sleep'] < 6])\n",
    "\n",
    "def classificar_sono(qualidade):\n",
    "  if qualidade in [4, 5]:\n",
    "      return 'Sono ruim'\n",
    "  elif qualidade in [6, 7]:\n",
    "      return 'Sono mediano'\n",
    "  elif qualidade in [8, 9]:\n",
    "      return 'Sono bom'\n",
    "  else:\n",
    "      return 'valor inválido'\n",
    "\n",
    "df['Classe'] = df['Quality of Sleep'].apply(classificar_sono)\n",
    "\n",
    "display(df)\n",
    "df = df.replace(['Sono ruim', 'Sono mediano', 'Sono bom'], list(range(len(df['Classe'].unique()))))\n",
    "display(df)\n",
    "df = df.drop(columns=['Quality of Sleep'])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Mostando os Histogramas de todas as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.hist(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), KNeighborsClassifier(n_neighbors=1)\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias do 1NN {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. KNN com 8 vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), KNeighborsClassifier(n_neighbors=8)\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias do KNN {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), GaussianNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Gaussiana {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), BernoulliNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Bernoulli {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        model = MultinomialNB()\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Multinomial {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 2: Redes Neurais Artificiais (Rede Perceptron Uni e Multicamadas).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para esta parte do trabalho final da disciplina, deverá ser feito:\n",
    "#### Utilizando a base de dados selecionada e utilizada nos trabalhos anteriores, implemente uma RNA que seja capaz de classificar/entender/resolver seu problema, de forma que:\n",
    "* Utilize a melhor base de treinamento, ou seja, você deverá conseguir obter os melhores exemplos para treinamento de acordo com as técnicas de ML utilizadas anteriormente. Este processo é manual, ou seja, você deve observar quais são os registros que fazem com que a rede \"erre\", eliminá-los da base de treinamento e adicionar registros mais apropriados, deste forma espera-se que a acurácia do sistema seja melhor. Lembre-se de manter pelo menos 100 registros em cada classe;\n",
    "* Tendo em mãos esta nova base de treinamento, execute novamente todos os testes nas diferentes técnicas de ML e compare os resultados com o que foi executado anteriormente (esta comparação deve ser textual e explicativa, colocada no arquivo texto e no Colab).\n",
    "* Implemente então uma RNA Perceptron de camada única e multicamadas com aprendizagem supervisionada e descreva os resultados.\n",
    "* Ao final, realize testes com 5 entradas de dados aleatórias e veja se o sistema realiza a classificação corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Melhor base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como a melhor base de dados definida anteriormente no trabalho de classificação foi utilizando o algorítmo com um modelo ````Gaussian()````, utilizaremos ele.\n",
    "> **NOTA:**\n",
    "> Por mais que esta seja a melhor base de dados, ela não treinada com os dados corretos, pois o algorítmo faz isso da própria maneira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), GaussianNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Gaussiana {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Testes e Comparações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo os teste com os conjuntos de treino e teste selecionados manualmente e comparando os resultados com os anteriores. Como definido no projeto anterior, utilizaremos o modelo Gaussiano pois foi o que mais se destacou entre os outros. Desta vez, ao invés de deixar o algorítmo definir os conjuntos de treino e teste, criaremos os conjuntos na mão, pegando 50% de cada classe para teste e os outros 50% para treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for test_size in np.arange(0.1, 1, 0.1):\n",
    "              x = df.drop('Classe', axis=1)\n",
    "              y = df['Classe']\n",
    "\n",
    "              scores = []\n",
    "        \n",
    "                for i in range(200):\n",
    "                  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "        \n",
    "                    scaler, model = StandardScaler(), GaussianNB()\n",
    "                  scaler.fit(x_train)\n",
    "\n",
    "                  x_train = scaler.transform(x_train)\n",
    "                  x_test = scaler.transform(x_test)\n",
    "\n",
    "                    model.fit(x_train, y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                  accuracy = accuracy_score(y_pred, y_test)\n",
    "                    scores.append(accuracy)\n",
    "\n",
    "              f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = [0,1,2]\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acurácias da Gaussiana {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):    \n",
    "    for class_label in df['Classe'].unique():\n",
    "        class_data = df[df['Classe'] == class_label]\n",
    "        class_50_teste = class_data.head(len(class_data) // 2)\n",
    "        class_50_treino = class_data.tail(len(class_data) // 2)\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for i in range(200):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(class_data.drop('Classe', axis=1), class_data['Classe'], test_size=float(test_size))\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            model = GaussianNB()\n",
    "\n",
    "            scaler.fit(x_train)\n",
    "            x_train_scaled = scaler.transform(x_train)\n",
    "            x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "            model.fit(x_train_scaled, y_train)\n",
    "            y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            scores.append(accuracy)\n",
    "            \n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Class: {class_label}\")\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = df['Classe'].unique()\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acurácias da Gaussiana para Classe {class_label} para {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Implementando a rede Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1. sklearn.linear_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):    \n",
    "    for class_label in df['Classe'].unique():\n",
    "        class_data = df[df['Classe'] == class_label]\n",
    "        class_50_teste = class_data.head(len(class_data) // 2)\n",
    "        class_50_treino = class_data.tail(len(class_data) // 2)\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for i in range(200):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(class_data.drop('Classe', axis=1), class_data['Classe'], test_size=float(test_size))\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            perceptron = Perceptron()\n",
    "\n",
    "            scaler.fit(x_train)\n",
    "            x_train_scaled = scaler.transform(x_train)\n",
    "            x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "            perceptron.fit(x_train_scaled, y_train)\n",
    "            y_pred = perceptron.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            scores.append(accuracy)\n",
    "            \n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Class: {class_label}\")\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = df['Classe'].unique()\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acurácias da Gaussiana para Classe {class_label} para {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
