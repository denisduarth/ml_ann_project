{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 1: Projeto Machine Learning (Algorítmo de Classificação)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Bibliotecas padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Bibliotecas sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "  accuracy_score,\n",
    "  confusion_matrix,\n",
    "  ConfusionMatrixDisplay,\n",
    "  f1_score,\n",
    "  classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Versão VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv', delimiter=',')\n",
    "df = df.drop(columns=['Person ID', 'Daily Steps', 'Heart Rate', 'Blood Pressure', 'BMI Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Versão Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/Sleep_health_and_lifestyle_dataset.csv', delimiter=';')\n",
    "# df = df.drop(columns=['Unnamed: 13','Unnamed: 14', 'Person ID', 'Daily Steps', 'Heart Rate', 'Blood Pressure', 'BMI Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Trocando valores string por valores inteiros em cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace(['Male', 'Female'], list(range(len(df['Gender'].unique()))))\n",
    "df['Sleep Disorder'] = df['Sleep Disorder'].replace(['None', 'Sleep Apnea', 'Insomnia'], (list(range(len(df['Sleep Disorder'].unique())))))\n",
    "df['Occupation'] = df['Occupation'].replace(df['Occupation'].unique(), list(range(len(df['Occupation'].unique())))) # type: ignore\n",
    "df['Sleep Disorder'].fillna(np.floor(df['Sleep Disorder'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criando a coluna \"Class\" a partir da coluna \"Quality of Sleep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[df['Quality of Sleep'] < 6])\n",
    "\n",
    "def classificar_sono(qualidade):\n",
    "  if qualidade in [4, 5]:\n",
    "      return 'Sono ruim'\n",
    "  elif qualidade in [6, 7]:\n",
    "      return 'Sono mediano'\n",
    "  elif qualidade in [8, 9]:\n",
    "      return 'Sono bom'\n",
    "  else:\n",
    "      return 'valor inválido'\n",
    "\n",
    "df['Class'] = df['Quality of Sleep'].apply(classificar_sono)\n",
    "\n",
    "display(df)\n",
    "df = df.replace(['Sono ruim', 'Sono mediano', 'Sono bom'], list(range(len(df['Class'].unique()))))\n",
    "display(df)\n",
    "df = df.drop(columns=['Quality of Sleep'])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Mostando os Histogramas de todas as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.hist(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), KNeighborsClassifier(n_neighbors=1)\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias do 1NN {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. KNN com 8 vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), KNeighborsClassifier(n_neighbors=8)\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias do KNN {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), GaussianNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Gaussiana {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), BernoulliNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Bernoulli {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Class', axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    scores = []\n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        model = MultinomialNB()\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acurácias da Multinomial {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 2: Redes Neurais Artificiais (Rede Perceptron Uni e Multicamadas).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para esta parte do trabalho final da disciplina, deverá ser feito:\n",
    "#### Utilizando a base de dados selecionada e utilizada nos trabalhos anteriores, implemente uma RNA que seja capaz de classificar/entender/resolver seu problema, de forma que:\n",
    "* Utilize a melhor base de treinamento, ou seja, você deverá conseguir obter os melhores exemplos para treinamento de acordo com as técnicas de ML utilizadas anteriormente. Este processo é manual, ou seja, você deve observar quais são os registros que fazem com que a rede \"erre\", eliminá-los da base de treinamento e adicionar registros mais apropriados, deste forma espera-se que a acurácia do sistema seja melhor. Lembre-se de manter pelo menos 100 registros em cada Class;\n",
    "* Tendo em mãos esta nova base de treinamento, execute novamente todos os testes nas diferentes técnicas de ML e compare os resultados com o que foi executado anteriormente (esta comparação deve ser textual e explicativa, colocada no arquivo texto e no Colab).\n",
    "* Implemente então uma RNA Perceptron de camada única e multicamadas com aprendizagem supervisionada e descreva os resultados.\n",
    "* Ao final, realize testes com 5 entradas de dados aleatórias e veja se o sistema realiza a classificação corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Testes e Comparações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo os teste com os conjuntos de treino e teste selecionados manualmente e comparando os resultados com os anteriores. Como definido no projeto anterior, utilizaremos o modelo Gaussiano pois foi o que mais se destacou entre os outros. Desta vez, ao invés de deixar o algorítmo definir os conjuntos de treino e teste, criaremos os conjuntos na mão, pegando 50% de cada Class para teste e os outros 50% para treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for test_size in np.arange(0.1, 1, 0.1):\n",
    "              x = df.drop('Class', axis=1)\n",
    "              y = df['Class']\n",
    "\n",
    "              scores = []\n",
    "        \n",
    "                for i in range(200):\n",
    "                  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "        \n",
    "                    scaler, model = StandardScaler(), GaussianNB()\n",
    "                  scaler.fit(x_train)\n",
    "\n",
    "                  x_train = scaler.transform(x_train)\n",
    "                  x_test = scaler.transform(x_test)\n",
    "\n",
    "                    model.fit(x_train, y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                  accuracy = accuracy_score(y_pred, y_test)\n",
    "                    scores.append(accuracy)\n",
    "\n",
    "              f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = [0,1,2]\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acurácias da Gaussiana {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):    \n",
    "    for class_label in df['Class'].unique():\n",
    "        class_data = df[df['Class'] == class_label]\n",
    "        class_50_teste = class_data.head(len(class_data) // 2)\n",
    "        class_50_treino = class_data.tail(len(class_data) // 2)\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for i in range(200):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(class_data.drop('Class', axis=1), class_data['Class'], test_size=float(test_size))\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            model = GaussianNB()\n",
    "\n",
    "            scaler.fit(x_train)\n",
    "            x_train_scaled = scaler.transform(x_train)\n",
    "            x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "            model.fit(x_train_scaled, y_train)\n",
    "            y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            scores.append(accuracy)\n",
    "            \n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Class: {class_label}\")\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = df['Class'].unique()\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acurácias da Gaussiana para Class {class_label} para {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Implementando a rede Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itens necessários para a criação do Perceptron\n",
    "- x (vetor de entrada com dados)\n",
    "- y (saída esperada)\n",
    "- Learning Rate (taxa de aprendizado)\n",
    "- Epochs (épocas)\n",
    "\n",
    "### Itens preenchidos aleatoriamente\n",
    "- weights (pesos)\n",
    "- bias (viés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Criando Class Perceptron\n",
    "# class Perceptron:\n",
    "#     # Definindo valores para o construtor\n",
    "#     def __init__(self, n_columns, n_Classs, learning_rate=0.01, n_iterations=1000):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.n_iterations = n_iterations\n",
    "        \n",
    "#         # Necessários para a definição dos pesos e o viés\n",
    "#         self.n_columns = n_columns\n",
    "#         self.n_Classs = n_Classs\n",
    "        \n",
    "#         # A coisa certa é inicializar os pesos e o viés com valores aleatórios\n",
    "#         self.weights = np.random.rand(self.n_columns, self.n_Classs)\n",
    "#         self.bias = np.random.rand(self.n_Classs)\n",
    "    \n",
    "#     # Função de ativação para definir os valores de acordo com os valores dos arrays do dataframe\n",
    "#     def bipolar_step_function(self, x):\n",
    "#         if x > 0:\n",
    "#             return 1\n",
    "#         elif x == 0:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             return -1\n",
    "\n",
    "#     def weighted_sum(self, x):\n",
    "#         multiply = np.multiply(x, self.weights)\n",
    "#         result = np.sum(multiply) - 1 * self.bias\n",
    "#         return result\n",
    "    \n",
    "#     def predict(self, x):\n",
    "#         linear_output = np.dot(x, self.weights) + self.bias\n",
    "#         y_predict = self.bipolar_step_function(linear_output)\n",
    "#         return y_predict\n",
    "    \n",
    "#     def output(self, x):\n",
    "#         weighted_sum = self.weighted_sum(x, self.weights) # type: ignore\n",
    "#         return self.bipolar_step_function(weighted_sum)\n",
    "    \n",
    "#     # new_weight = weight + learning_rate * Xi * error\n",
    "#     def update_weights(self, x, expected_value, obtained_value):\n",
    "#         error = expected_value - obtained_value\n",
    "#         new_weights = self.weights + self.learning_rate * x * error\n",
    "#         new_bias = self.bias + self.learning_rate * -1 * error\n",
    "#         return new_weights, new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perceptron(x, y, learning_rate, epochs):\n",
    "#     weights = np.zeros(len(x[0]))\n",
    "#     n_iters = 0\n",
    "#     y_vet = np.ones(len(y))\n",
    "#     errors = np.ones(len(y))\n",
    "\n",
    "#     j = [] # erro quadrático médio (vetor que irá receber o resultado do erro)\n",
    "\n",
    "#     while n_iters < epochs:\n",
    "#         for i in range(0, len(x)):\n",
    "#             f = np.dot(x[i], weights)\n",
    "\n",
    "#             if(f > 0):\n",
    "#                 y_ = 1\n",
    "#             elif f == 0:\n",
    "#                 y_ = 0\n",
    "#             else:\n",
    "#                 y_ = -1\n",
    "            \n",
    "#             y_vet[i] = y_\n",
    "\n",
    "#             for j in range(0, len(weights)):\n",
    "#                 weights[j] = weights[j] + learning_rate * (y[i] - y_) * x[i][j] # type: ignore\n",
    "            \n",
    "#             n_iters+=1\n",
    "        \n",
    "#         for i in range(0, len(y)):\n",
    "#             errors[i] = y[i] - y_vet**2\n",
    "#             j.append(0.5 * np.sum(errors))\n",
    "#     return weights, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df.drop('Class',axis=1)\n",
    "# y = np.where(df['Class'] == 0, 0, np.where(df['Class'] == 1, 1, 2))\n",
    "\n",
    "# print(perceptron(x, y, 0.5, 50)[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Perceptron Unicamada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in [0.3, 0.5, 0.7]:\n",
    "    x = np.array(df.loc[:199, 'Age']).reshape(-1,1)\n",
    "    y = np.array(df.loc[:199, 'Class']).reshape(-1,1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "    scaler, perceptron = StandardScaler(), Perceptron(max_iter=2000, verbose=2)\n",
    "\n",
    "    scaler.fit(x_train)\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    perceptron.fit(x_train_scaled, y_train)\n",
    "\n",
    "    y_pred = perceptron.predict(x_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = df['Class'].unique()\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(x_test, y_test, label=\"Reais\")\n",
    "    plt.scatter(x_test, y_pred, label=\"Previsão\")\n",
    "    plt.yticks(np.arange(0,3))\n",
    "    plt.xlabel('Idades')\n",
    "    plt.ylabel('Class')\n",
    "    plt.legend(loc=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Perceptron Multicamada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in [0.3, 0.5, 0.7]:\n",
    "    x = np.array(df.loc[:199, 'Age']).reshape(-1,1)\n",
    "    y = np.array(df.loc[:199, 'Class']).reshape(-1,1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "    scaler, perceptron = StandardScaler(),  MLPClassifier(\n",
    "        hidden_layer_sizes=(10,5), \n",
    "        max_iter=2000, verbose=True, \n",
    "        learning_rate='constant', \n",
    "        learning_rate_init=0.1\n",
    "    )\n",
    "\n",
    "    scaler.fit(x_train)\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    perceptron.fit(x_train_scaled, y_train)\n",
    "\n",
    "    y_pred = perceptron.predict(x_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = df['Class'].unique()\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f\"Relação de erros e acertos para Perceptron Multicamada {test_size:.2f}\")\n",
    "    plt.scatter(x_test, y_test, label=\"Reais\")\n",
    "    plt.scatter(x_test, y_pred, label=\"Previsão\")\n",
    "    plt.yticks(np.arange(0,3))\n",
    "    plt.xlabel('Idades')\n",
    "    plt.ylabel('Class')\n",
    "    plt.legend(loc=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
