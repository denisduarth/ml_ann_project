{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 1: Projeto Machine Learning (Algor√≠tmo de Classifica√ß√£o)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "  accuracy_score,\n",
    "  confusion_matrix,\n",
    "  ConfusionMatrixDisplay,\n",
    "  f1_score,\n",
    "  classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Vers√£o VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv', delimiter=',')\n",
    "df = df.drop(columns=['Person ID', 'Daily Steps', 'Heart Rate', 'Blood Pressure', 'BMI Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Vers√£o Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/Sleep_health_and_lifestyle_dataset.csv', delimiter=';')\n",
    "# df = df.drop(columns=['Unnamed: 13','Unnamed: 14', 'Person ID', 'Daily Steps', 'Heart Rate', 'Blood Pressure', 'BMI Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Trocando valores string por valores inteiros em cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace(['Male', 'Female'], list(range(len(df['Gender'].unique()))))\n",
    "df['Sleep Disorder'] = df['Sleep Disorder'].replace(['None', 'Sleep Apnea', 'Insomnia'], (list(range(len(df['Sleep Disorder'].unique())))))\n",
    "df['Occupation'] = df['Occupation'].replace(df['Occupation'].unique(), list(range(len(df['Occupation'].unique())))) # type: ignore\n",
    "df['Sleep Disorder'].fillna(np.floor(df['Sleep Disorder'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criando a coluna \"Classe\" a partir da coluna \"Quality of Sleep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.loc[df['Quality of Sleep'] < 6])\n",
    "\n",
    "def classificar_sono(qualidade):\n",
    "  if qualidade in [4, 5]:\n",
    "      return 'Sono ruim'\n",
    "  elif qualidade in [6, 7]:\n",
    "      return 'Sono mediano'\n",
    "  elif qualidade in [8, 9]:\n",
    "      return 'Sono bom'\n",
    "  else:\n",
    "      return 'valor inv√°lido'\n",
    "\n",
    "df['Classe'] = df['Quality of Sleep'].apply(classificar_sono)\n",
    "\n",
    "display(df)\n",
    "df = df.replace(['Sono ruim', 'Sono mediano', 'Sono bom'], list(range(len(df['Classe'].unique()))))\n",
    "display(df)\n",
    "df = df.drop(columns=['Quality of Sleep'])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Mostando os Histogramas de todas as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.hist(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), KNeighborsClassifier(n_neighbors=1)\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acur√°cias do 1NN {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. KNN com 8 vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), KNeighborsClassifier(n_neighbors=8)\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acur√°cias do KNN {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), GaussianNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acur√°cias da Gaussiana {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), BernoulliNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acur√°cias da Bernoulli {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        model = MultinomialNB()\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acur√°cias da Multinomial {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parte 2: Redes Neurais Artificiais (Rede Perceptron Uni e Multicamadas).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para esta parte do trabalho final da disciplina, dever√° ser feito:\n",
    "#### Utilizando a base de dados selecionada e utilizada nos trabalhos anteriores, implemente uma RNA que seja capaz de classificar/entender/resolver seu problema, de forma que:\n",
    "* Utilize a melhor base de treinamento, ou seja, voc√™ dever√° conseguir obter os melhores exemplos para treinamento de acordo com as t√©cnicas de ML utilizadas anteriormente. Este processo √© manual, ou seja, voc√™ deve observar quais s√£o os registros que fazem com que a rede \"erre\", elimin√°-los da base de treinamento e adicionar registros mais apropriados, deste forma espera-se que a acur√°cia do sistema seja melhor. Lembre-se de manter pelo menos 100 registros em cada classe;\n",
    "* Tendo em m√£os esta nova base de treinamento, execute novamente todos os testes nas diferentes t√©cnicas de ML e compare os resultados com o que foi executado anteriormente (esta compara√ß√£o deve ser textual e explicativa, colocada no arquivo texto e no Colab).\n",
    "* Implemente ent√£o uma RNA Perceptron de camada √∫nica e multicamadas com aprendizagem supervisionada e descreva os resultados.\n",
    "* Ao final, realize testes com 5 entradas de dados aleat√≥rias e veja se o sistema realiza a classifica√ß√£o corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Melhor base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como a melhor base de dados definida anteriormente no trabalho de classifica√ß√£o foi utilizando o algor√≠tmo com um modelo ````Gaussian()````, utilizaremos ele.\n",
    "> **NOTA:**\n",
    "> Por mais que esta seja a melhor base de dados, ela n√£o treinada com os dados corretos, pois o algor√≠tmo faz isso da pr√≥pria maneira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    y = df['Classe']\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "\n",
    "        scaler, model = StandardScaler(), GaussianNB()\n",
    "        scaler.fit(x_train)\n",
    "\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = [0,1,2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure()\n",
    "    sns.histplot(scores)\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Acur√°cias da Gaussiana {test_size:.1f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Testes e Compara√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo os teste com os conjuntos de treino e teste selecionados manualmente e comparando os resultados com os anteriores. Como definido no projeto anterior, utilizaremos o modelo Gaussiano pois foi o que mais se destacou entre os outros. Desta vez, ao inv√©s de deixar o algor√≠tmo definir os conjuntos de treino e teste, criaremos os conjuntos na m√£o, pegando 50% de cada classe para teste e os outros 50% para treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for test_size in np.arange(0.1, 1, 0.1):\n",
    "              x = df.drop('Classe', axis=1)\n",
    "              y = df['Classe']\n",
    "\n",
    "              scores = []\n",
    "        \n",
    "                for i in range(200):\n",
    "                  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "        \n",
    "                    scaler, model = StandardScaler(), GaussianNB()\n",
    "                  scaler.fit(x_train)\n",
    "\n",
    "                  x_train = scaler.transform(x_train)\n",
    "                  x_test = scaler.transform(x_test)\n",
    "\n",
    "                    model.fit(x_train, y_train)\n",
    "                    y_pred = model.predict(x_test)\n",
    "                  accuracy = accuracy_score(y_pred, y_test)\n",
    "                    scores.append(accuracy)\n",
    "\n",
    "              f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = [0,1,2]\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acur√°cias da Gaussiana {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):    \n",
    "    for class_label in df['Classe'].unique():\n",
    "        class_data = df[df['Classe'] == class_label]\n",
    "        class_50_teste = class_data.head(len(class_data) // 2)\n",
    "        class_50_treino = class_data.tail(len(class_data) // 2)\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for i in range(200):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(class_data.drop('Classe', axis=1), class_data['Classe'], test_size=float(test_size))\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            model = GaussianNB()\n",
    "\n",
    "            scaler.fit(x_train)\n",
    "            x_train_scaled = scaler.transform(x_train)\n",
    "            x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "            model.fit(x_train_scaled, y_train)\n",
    "            y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            scores.append(accuracy)\n",
    "            \n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Class: {class_label}\")\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "        labels = df['Classe'].unique()\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        plt.figure()\n",
    "        sns.histplot(scores)\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Acur√°cias da Gaussiana para Classe {class_label} para {test_size:.1f}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Implementando a rede Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> n_classes = n√∫mero de classes da coluna que se deseja trabalhar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itens necess√°rios para a cria√ß√£o do Perceptron\n",
    "- x (vetor de entrada com dados)\n",
    "- y (sa√≠da esperada)\n",
    "- Threshold (limiar)\n",
    "- Learning Rate (taxa de aprendizado)\n",
    "- Epochs (√©pocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando classe Perceptron\n",
    "class Perceptron:\n",
    "    # Definindo valores para o construtor\n",
    "    def __init__(self, n_columns, n_classes, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        \n",
    "        # Necess√°rios para a defini√ß√£o dos pesos e o vi√©s\n",
    "        self.n_columns = n_columns\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # A coisa certa √© inicializar os pesos e o vi√©s com valores aleat√≥rios\n",
    "        self.weights = np.random.rand(self.n_columns, self.n_classes)\n",
    "        self.bias = np.random.rand(self.n_classes)\n",
    "    \n",
    "    # Fun√ß√£o de ativa√ß√£o para definir os valores de acordo com os valores dos arrays do dataframe\n",
    "    def bipolar_step_function(self, x):\n",
    "        if x > 0:\n",
    "            return 1\n",
    "        elif x == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def weighted_sum(self, x):\n",
    "        multiply = np.multiply(x, self.weights)\n",
    "        result = np.sum(multiply) - 1 * self.bias\n",
    "        return result\n",
    "    \n",
    "    def predict(self, x):\n",
    "        linear_output = np.dot(x, self.weights) + self.bias\n",
    "        y_predict = self.bipolar_step_function(linear_output)\n",
    "        return y_predict\n",
    "    \n",
    "    def output(self, x):\n",
    "        weighted_sum = self.weighted_sum(x, self.weights) # type: ignore\n",
    "        return self.bipolar_step_function(weighted_sum)\n",
    "    \n",
    "    # new_weight = weight + learning_rate * Xi * error\n",
    "    def update_weights(self, x, expected_value, obtained_value):\n",
    "        error = expected_value - obtained_value\n",
    "        new_weights = self.weights + self.learning_rate * x * error\n",
    "        new_bias = self.bias + self.learning_rate * -1 * error\n",
    "        return new_weights, new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x, y, learning_rate, epochs):\n",
    "    weights = np.zeros(len(x[0]))\n",
    "    n_iters = 0\n",
    "    y_vet = np.ones(len(y))\n",
    "    errors = np.ones(len(y))\n",
    "\n",
    "    j = [] # erro quadr√°tico m√©dio (vetor que ir√° receber o resultado do erro)\n",
    "\n",
    "    while n_iters < epochs:\n",
    "        for i in range(0, len(x)):\n",
    "            f = np.dot(x[i], weights)\n",
    "\n",
    "            if(f > 0):\n",
    "                y_ = 1\n",
    "            elif f == 0:\n",
    "                y_ = 0\n",
    "            else:\n",
    "                y_ = -1\n",
    "            \n",
    "            y_vet[i] = y_\n",
    "\n",
    "            for j in range(0, len(weights)):\n",
    "                weights[j] = weights[j] + learning_rate * (y[i] - y_) * x[i][j] # type: ignore\n",
    "            \n",
    "            n_iters+=1\n",
    "        \n",
    "        for i in range(0, len(y)):\n",
    "            errors[i] = y[i] - y_vet**2\n",
    "            j.append(0.5 * np.sum(errors))\n",
    "    return weights, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Classe',axis=1)\n",
    "y = np.where(df['Classe'] == 0, 0, np.where(df['Classe'] == 1, 1, 2))\n",
    "\n",
    "print(perceptron(x, y, 0.5, 50)[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Perceptron meh üíÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in np.arange(0.1, 1, 0.1):\n",
    "    x = df.drop('Classe', axis=1)\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df['Classe'])\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=float(test_size))\n",
    "        y_test = y_test[~np.isnan(y_test)]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        perceptron = Perceptron(random_state=0)\n",
    "\n",
    "        scaler.fit(x_train)\n",
    "        x_train_scaled = scaler.transform(x_train)\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "        perceptron.fit(x_train_scaled, y_train)\n",
    "        y_pred = perceptron.predict(x_test_scaled)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    labels = df['Classe'].unique()\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    weights = perceptron.coef_[0]\n",
    "    bias = perceptron.intercept_[0]\n",
    "\n",
    "    # Plot the perceptron decision boundary\n",
    "    x_min, x_max = x['Age'].min(), x['Age'].max()\n",
    "    y_min, y_max = x['Physical Activity Level'].min(), x['Physical Activity Level'].max()\n",
    "\n",
    "    def perceptron_decision_boundary(model, x_min, x_max, y_min, y_max):\n",
    "        # Generate a grid of points\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "        # Flatten the grid for predictions\n",
    "        grid_points = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "\n",
    "        # Predict the class for each point in the grid\n",
    "        z = model.predict(grid_points)\n",
    "\n",
    "        # Reshape the predicted class into a 2D array\n",
    "        z = z.reshape(xx.shape)\n",
    "\n",
    "        return xx, yy, z\n",
    "\n",
    "    # Get the decision boundary for the last iteration (you might want to choose a specific iteration)\n",
    "    z = perceptron_decision_boundary(perceptron, x_min, x_max, y_min, y_max)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.contourf(z[0], z[1], z[2], cmap='coolwarm', alpha=0.8)\n",
    "    plt.scatter(x['Age'], x['Physical Activity Level'], c=y)  # Scatter plot your data points\n",
    "    plt.title(f\"Perceptron Decision Boundary (Test Size: {test_size:.1f})\")\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.ylabel(\"Physical Activity Level\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    sns.histplot(scores, label=f\"Test Size: {test_size}\")\n",
    "    plt.yticks([])\n",
    "    plt.legend()\n",
    "    plt.title(\"Distribution of Accuracy Scores for Perceptron\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
